# RAG Chatbot with Feedback Loop

## ğŸ” Overview
This project implements a Retrieval-Augmented Generation (RAG) system with a feedback loop. It supports document ingestion, chunking, vector storage, and response generation using LLMs.

## âš™ï¸ Features
-## ğŸ”§ Features
- Chunk documents using custom logic
- Generate vector embeddings using OpenAI or Transformers
- Store vectors using FAISS or ChromaDB
- Retrieve relevant chunks for context-aware responses
- Use LangChain to build prompt chains
- Feedback loop for improving system responses

## ğŸ§± Architecture
 <img width="468" alt="image" src="https://github.com/user-attachments/assets/b65a5646-fbfb-4c59-b05b-7aaede9a1312" />


## ğŸ“¦ Project Structure

â”œâ”€â”€ rag_pipeline/         # Main logic: chunking, embedding, retrieval
â”œâ”€â”€ utils/                # Helper functions
â”œâ”€â”€ main.py               # Entry point
â”œâ”€â”€ requirements.txt      # Dependencies
â”œâ”€â”€ .env.example          # Example environment variables
â”œâ”€â”€ README.md             # This file
â””â”€â”€ tests/                # Unit and integration tests


## ğŸ› ï¸ Setup Instructions

###  -Clone the repo
   '''bash
      git clone  https://github.com/VinayKumar939/RAG_CHATBOT.git 
      cd RAG_CHATBOT

### -Create Virtual Environment
   python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

###  -Install Dependencies
  pip install -r requirements.txt
  
### -Configure  Environment 
Create a .env file based on .env.example with API keys, DB configs, etc.

### How to Run the App**
### Running the App
```bash python main.py

### Sample Use Case


###Contributors
- Vinay Kumar Mannava








   





